{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "def initialize_uninitialized(sess):\n",
    "    global_vars          = tf.global_variables()\n",
    "    is_not_initialized   = sess.run([tf.is_variable_initialized(var) for var in global_vars])\n",
    "    not_initialized_vars = [v for (v, f) in zip(global_vars, is_not_initialized) if not f]\n",
    "\n",
    "    #print [str(i.name) for i in not_initialized_vars] # only for testing\n",
    "    if len(not_initialized_vars):\n",
    "        sess.run(tf.variables_initializer(not_initialized_vars))\n",
    "        \n",
    "    list_of_variables = tf.global_variables()\n",
    "   \n",
    "    uninitialized_variables = sess.run(tf.report_uninitialized_variables(list_of_variables))\n",
    "    \n",
    "    if len(uninitialized_variables)>0:\n",
    "        return uninitialized_variables\n",
    "    else:\n",
    "        return \"all_variables_initialized\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prepare some input and label for a classification problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe=OneHotEncoder()\n",
    "ohe.fit(np.array(['A','C','G','T']).reshape(-1,1))\n",
    "\n",
    "seq=[]\n",
    "label=[]\n",
    "for i in range(1000):\n",
    "    tmp=np.array(random.choices('ACGT',k=100))\n",
    "    seq.append(ohe.transform(tmp.reshape(-1,1)).toarray())\n",
    "    label.append(random.choices([0,1],k=1))\n",
    "\n",
    "seq=np.array(seq)\n",
    "label=np.array(label).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train and save the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0911 21:59:09.936074  2580 deprecation.py:323] From <ipython-input-3-cb969bea8024>:5: conv1d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.keras.layers.Conv1D` instead.\n",
      "W0911 21:59:09.941073  2580 deprecation.py:506] From c:\\users\\yynst\\anaconda3\\envs\\gpu\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0911 21:59:10.043072  2580 deprecation.py:323] From <ipython-input-3-cb969bea8024>:6: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.BatchNormalization instead.  In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.batch_normalization` documentation).\n",
      "W0911 21:59:10.121072  2580 deprecation.py:323] From <ipython-input-3-cb969bea8024>:7: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dropout instead.\n",
      "W0911 21:59:10.176074  2580 deprecation.py:323] From <ipython-input-3-cb969bea8024>:8: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "W0911 21:59:10.373072  2580 deprecation.py:323] From <ipython-input-3-cb969bea8024>:9: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "with tf.variable_scope(name_or_scope='ref'):\n",
    "    v1 = tf.placeholder(tf.float32,shape=(None,100,4), name=\"v1\") \n",
    "    v2=tf.layers.conv1d(inputs=v1,filters=1,kernel_size=8,strides=1,padding='valid',\n",
    "                        data_format='channels_last',use_bias=False,name='conv0',activation='relu')\n",
    "    v3=tf.layers.batch_normalization(inputs=v2,axis=-1,name='bn')\n",
    "    v4=tf.layers.dropout(inputs=v3,rate=0.05,name='drop')\n",
    "    v5=tf.layers.flatten(inputs=v4,name='flat')\n",
    "    v6=tf.layers.dense(inputs=v5,units=1,activation='sigmoid')\n",
    "    \n",
    "with tf.variable_scope(name_or_scope='criteria'):\n",
    "    target_op=tf.placeholder(tf.float32,shape=(None,1),name='target')\n",
    "    loss=tf.reduce_mean(tf.square(tf.subtract(target_op,v6)),name='loss') \n",
    "    opt=tf.train.AdamOptimizer(learning_rate=0.01,\n",
    "                               name='ref_adam').minimize(loss,\n",
    "                                                name='ref_opt',var_list=tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES)\n",
    "                                                        )\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# cpu\n",
    "#with tf.Session() as sess: \n",
    "# gpu\n",
    "gpu_options=tf.GPUOptions(allow_growth=True)\n",
    "sess=tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for _ in range(10):\n",
    "    print(_)\n",
    "    sess.run([loss,opt],feed_dict={v1:seq,target_op:label}) \n",
    "\n",
    "saver.save(sess, \"./model/model_test\")\n",
    "\n",
    "graph=tf.get_default_graph()\n",
    "writer = tf.summary.FileWriter(\"./model/model_graph\", graph=sess.graph,filename_suffix='reference')\n",
    "#print(tf.pl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load the modify the network structure, loss, optimizer, and re-train it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0911 22:00:45.197487 23448 deprecation.py:323] From c:\\users\\yynst\\anaconda3\\envs\\gpu\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "# cpu\n",
    "# sess=tf.Session() \n",
    "# gpu\n",
    "gpu_options=tf.GPUOptions(allow_growth=True)\n",
    "sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "    \n",
    "saver = tf.train.import_meta_graph(\"./model/model_test.meta\")\n",
    "saver.restore(sess,tf.train.latest_checkpoint('./model/'))\n",
    "graph=tf.get_default_graph()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ref/v1\n",
      "ref/conv0/kernel/Initializer/random_uniform/shape\n",
      "ref/conv0/kernel/Initializer/random_uniform/min\n",
      "ref/conv0/kernel/Initializer/random_uniform/max\n",
      "ref/conv0/kernel/Initializer/random_uniform/RandomUniform\n",
      "ref/conv0/kernel/Initializer/random_uniform/sub\n",
      "ref/conv0/kernel/Initializer/random_uniform/mul\n",
      "ref/conv0/kernel/Initializer/random_uniform\n",
      "ref/conv0/kernel\n",
      "ref/conv0/kernel/Assign\n",
      "ref/conv0/kernel/read\n",
      "ref/conv0/dilation_rate\n",
      "ref/conv0/conv1d/ExpandDims/dim\n",
      "ref/conv0/conv1d/ExpandDims\n",
      "ref/conv0/conv1d/ExpandDims_1/dim\n",
      "ref/conv0/conv1d/ExpandDims_1\n",
      "ref/conv0/conv1d\n",
      "ref/conv0/conv1d/Squeeze\n",
      "ref/conv0/Relu\n",
      "ref/bn/gamma/Initializer/ones\n",
      "ref/bn/gamma\n",
      "ref/bn/gamma/Assign\n",
      "ref/bn/gamma/read\n",
      "ref/bn/beta/Initializer/zeros\n",
      "ref/bn/beta\n",
      "ref/bn/beta/Assign\n",
      "ref/bn/beta/read\n",
      "ref/bn/moving_mean/Initializer/zeros\n",
      "ref/bn/moving_mean\n",
      "ref/bn/moving_mean/Assign\n",
      "ref/bn/moving_mean/read\n",
      "ref/bn/moving_variance/Initializer/ones\n",
      "ref/bn/moving_variance\n",
      "ref/bn/moving_variance/Assign\n",
      "ref/bn/moving_variance/read\n",
      "ref/bn/batchnorm/add/y\n",
      "ref/bn/batchnorm/add\n",
      "ref/bn/batchnorm/Rsqrt\n",
      "ref/bn/batchnorm/mul\n",
      "ref/bn/batchnorm/mul_1\n",
      "ref/bn/batchnorm/mul_2\n",
      "ref/bn/batchnorm/sub\n",
      "ref/bn/batchnorm/add_1\n",
      "ref/drop/Identity\n",
      "ref/flat/Shape\n",
      "ref/flat/strided_slice/stack\n",
      "ref/flat/strided_slice/stack_1\n",
      "ref/flat/strided_slice/stack_2\n",
      "ref/flat/strided_slice\n",
      "ref/flat/Reshape/shape/1\n",
      "ref/flat/Reshape/shape\n",
      "ref/flat/Reshape\n",
      "ref/dense/kernel/Initializer/random_uniform/shape\n",
      "ref/dense/kernel/Initializer/random_uniform/min\n",
      "ref/dense/kernel/Initializer/random_uniform/max\n",
      "ref/dense/kernel/Initializer/random_uniform/RandomUniform\n",
      "ref/dense/kernel/Initializer/random_uniform/sub\n",
      "ref/dense/kernel/Initializer/random_uniform/mul\n",
      "ref/dense/kernel/Initializer/random_uniform\n",
      "ref/dense/kernel\n",
      "ref/dense/kernel/Assign\n",
      "ref/dense/kernel/read\n",
      "ref/dense/bias/Initializer/zeros\n",
      "ref/dense/bias\n",
      "ref/dense/bias/Assign\n",
      "ref/dense/bias/read\n",
      "ref/dense/MatMul\n",
      "ref/dense/BiasAdd\n",
      "ref/dense/Sigmoid\n",
      "target\n",
      "Sub\n",
      "Square\n",
      "Const\n",
      "loss\n",
      "gradients/Shape\n",
      "gradients/grad_ys_0\n",
      "gradients/Fill\n",
      "gradients/loss_grad/Reshape/shape\n",
      "gradients/loss_grad/Reshape\n",
      "gradients/loss_grad/Shape\n",
      "gradients/loss_grad/Tile\n",
      "gradients/loss_grad/Shape_1\n",
      "gradients/loss_grad/Shape_2\n",
      "gradients/loss_grad/Const\n",
      "gradients/loss_grad/Prod\n",
      "gradients/loss_grad/Const_1\n",
      "gradients/loss_grad/Prod_1\n",
      "gradients/loss_grad/Maximum/y\n",
      "gradients/loss_grad/Maximum\n",
      "gradients/loss_grad/floordiv\n",
      "gradients/loss_grad/Cast\n",
      "gradients/loss_grad/truediv\n",
      "gradients/Square_grad/Const\n",
      "gradients/Square_grad/Mul\n",
      "gradients/Square_grad/Mul_1\n",
      "gradients/Sub_grad/Shape\n",
      "gradients/Sub_grad/Shape_1\n",
      "gradients/Sub_grad/BroadcastGradientArgs\n",
      "gradients/Sub_grad/Sum\n",
      "gradients/Sub_grad/Reshape\n",
      "gradients/Sub_grad/Sum_1\n",
      "gradients/Sub_grad/Neg\n",
      "gradients/Sub_grad/Reshape_1\n",
      "gradients/Sub_grad/tuple/group_deps\n",
      "gradients/Sub_grad/tuple/control_dependency\n",
      "gradients/Sub_grad/tuple/control_dependency_1\n",
      "gradients/ref/dense/Sigmoid_grad/SigmoidGrad\n",
      "gradients/ref/dense/BiasAdd_grad/BiasAddGrad\n",
      "gradients/ref/dense/BiasAdd_grad/tuple/group_deps\n",
      "gradients/ref/dense/BiasAdd_grad/tuple/control_dependency\n",
      "gradients/ref/dense/BiasAdd_grad/tuple/control_dependency_1\n",
      "gradients/ref/dense/MatMul_grad/MatMul\n",
      "gradients/ref/dense/MatMul_grad/MatMul_1\n",
      "gradients/ref/dense/MatMul_grad/tuple/group_deps\n",
      "gradients/ref/dense/MatMul_grad/tuple/control_dependency\n",
      "gradients/ref/dense/MatMul_grad/tuple/control_dependency_1\n",
      "gradients/ref/flat/Reshape_grad/Shape\n",
      "gradients/ref/flat/Reshape_grad/Reshape\n",
      "gradients/ref/bn/batchnorm/add_1_grad/Shape\n",
      "gradients/ref/bn/batchnorm/add_1_grad/Shape_1\n",
      "gradients/ref/bn/batchnorm/add_1_grad/BroadcastGradientArgs\n",
      "gradients/ref/bn/batchnorm/add_1_grad/Sum\n",
      "gradients/ref/bn/batchnorm/add_1_grad/Reshape\n",
      "gradients/ref/bn/batchnorm/add_1_grad/Sum_1\n",
      "gradients/ref/bn/batchnorm/add_1_grad/Reshape_1\n",
      "gradients/ref/bn/batchnorm/add_1_grad/tuple/group_deps\n",
      "gradients/ref/bn/batchnorm/add_1_grad/tuple/control_dependency\n",
      "gradients/ref/bn/batchnorm/add_1_grad/tuple/control_dependency_1\n",
      "gradients/ref/bn/batchnorm/mul_1_grad/Shape\n",
      "gradients/ref/bn/batchnorm/mul_1_grad/Shape_1\n",
      "gradients/ref/bn/batchnorm/mul_1_grad/BroadcastGradientArgs\n",
      "gradients/ref/bn/batchnorm/mul_1_grad/Mul\n",
      "gradients/ref/bn/batchnorm/mul_1_grad/Sum\n",
      "gradients/ref/bn/batchnorm/mul_1_grad/Reshape\n",
      "gradients/ref/bn/batchnorm/mul_1_grad/Mul_1\n",
      "gradients/ref/bn/batchnorm/mul_1_grad/Sum_1\n",
      "gradients/ref/bn/batchnorm/mul_1_grad/Reshape_1\n",
      "gradients/ref/bn/batchnorm/mul_1_grad/tuple/group_deps\n",
      "gradients/ref/bn/batchnorm/mul_1_grad/tuple/control_dependency\n",
      "gradients/ref/bn/batchnorm/mul_1_grad/tuple/control_dependency_1\n",
      "gradients/ref/bn/batchnorm/sub_grad/Neg\n",
      "gradients/ref/bn/batchnorm/sub_grad/tuple/group_deps\n",
      "gradients/ref/bn/batchnorm/sub_grad/tuple/control_dependency\n",
      "gradients/ref/bn/batchnorm/sub_grad/tuple/control_dependency_1\n",
      "gradients/ref/conv0/Relu_grad/ReluGrad\n",
      "gradients/ref/bn/batchnorm/mul_2_grad/Mul\n",
      "gradients/ref/bn/batchnorm/mul_2_grad/Mul_1\n",
      "gradients/ref/bn/batchnorm/mul_2_grad/tuple/group_deps\n",
      "gradients/ref/bn/batchnorm/mul_2_grad/tuple/control_dependency\n",
      "gradients/ref/bn/batchnorm/mul_2_grad/tuple/control_dependency_1\n",
      "gradients/ref/conv0/conv1d/Squeeze_grad/Shape\n",
      "gradients/ref/conv0/conv1d/Squeeze_grad/Reshape\n",
      "gradients/AddN\n",
      "gradients/ref/bn/batchnorm/mul_grad/Mul\n",
      "gradients/ref/bn/batchnorm/mul_grad/Mul_1\n",
      "gradients/ref/bn/batchnorm/mul_grad/tuple/group_deps\n",
      "gradients/ref/bn/batchnorm/mul_grad/tuple/control_dependency\n",
      "gradients/ref/bn/batchnorm/mul_grad/tuple/control_dependency_1\n",
      "gradients/ref/conv0/conv1d_grad/ShapeN\n",
      "gradients/ref/conv0/conv1d_grad/Conv2DBackpropInput\n",
      "gradients/ref/conv0/conv1d_grad/Conv2DBackpropFilter\n",
      "gradients/ref/conv0/conv1d_grad/tuple/group_deps\n",
      "gradients/ref/conv0/conv1d_grad/tuple/control_dependency\n",
      "gradients/ref/conv0/conv1d_grad/tuple/control_dependency_1\n",
      "gradients/ref/conv0/conv1d/ExpandDims_1_grad/Shape\n",
      "gradients/ref/conv0/conv1d/ExpandDims_1_grad/Reshape\n",
      "beta1_power/initial_value\n",
      "beta1_power\n",
      "beta1_power/Assign\n",
      "beta1_power/read\n",
      "beta2_power/initial_value\n",
      "beta2_power\n",
      "beta2_power/Assign\n",
      "beta2_power/read\n",
      "ref/conv0/kernel/Adam/Initializer/zeros\n",
      "ref/conv0/kernel/Adam\n",
      "ref/conv0/kernel/Adam/Assign\n",
      "ref/conv0/kernel/Adam/read\n",
      "ref/conv0/kernel/Adam_1/Initializer/zeros\n",
      "ref/conv0/kernel/Adam_1\n",
      "ref/conv0/kernel/Adam_1/Assign\n",
      "ref/conv0/kernel/Adam_1/read\n",
      "ref/bn/gamma/Adam/Initializer/zeros\n",
      "ref/bn/gamma/Adam\n",
      "ref/bn/gamma/Adam/Assign\n",
      "ref/bn/gamma/Adam/read\n",
      "ref/bn/gamma/Adam_1/Initializer/zeros\n",
      "ref/bn/gamma/Adam_1\n",
      "ref/bn/gamma/Adam_1/Assign\n",
      "ref/bn/gamma/Adam_1/read\n",
      "ref/bn/beta/Adam/Initializer/zeros\n",
      "ref/bn/beta/Adam\n",
      "ref/bn/beta/Adam/Assign\n",
      "ref/bn/beta/Adam/read\n",
      "ref/bn/beta/Adam_1/Initializer/zeros\n",
      "ref/bn/beta/Adam_1\n",
      "ref/bn/beta/Adam_1/Assign\n",
      "ref/bn/beta/Adam_1/read\n",
      "ref/dense/kernel/Adam/Initializer/zeros\n",
      "ref/dense/kernel/Adam\n",
      "ref/dense/kernel/Adam/Assign\n",
      "ref/dense/kernel/Adam/read\n",
      "ref/dense/kernel/Adam_1/Initializer/zeros\n",
      "ref/dense/kernel/Adam_1\n",
      "ref/dense/kernel/Adam_1/Assign\n",
      "ref/dense/kernel/Adam_1/read\n",
      "ref/dense/bias/Adam/Initializer/zeros\n",
      "ref/dense/bias/Adam\n",
      "ref/dense/bias/Adam/Assign\n",
      "ref/dense/bias/Adam/read\n",
      "ref/dense/bias/Adam_1/Initializer/zeros\n",
      "ref/dense/bias/Adam_1\n",
      "ref/dense/bias/Adam_1/Assign\n",
      "ref/dense/bias/Adam_1/read\n",
      "Adam/learning_rate\n",
      "Adam/beta1\n",
      "Adam/beta2\n",
      "Adam/epsilon\n",
      "Adam/update_ref/conv0/kernel/ApplyAdam\n",
      "Adam/update_ref/bn/gamma/ApplyAdam\n",
      "Adam/update_ref/bn/beta/ApplyAdam\n",
      "Adam/update_ref/dense/kernel/ApplyAdam\n",
      "Adam/update_ref/dense/bias/ApplyAdam\n",
      "Adam/mul\n",
      "Adam/Assign\n",
      "Adam/mul_1\n",
      "Adam/Assign_1\n",
      "Adam\n",
      "save/filename/input\n",
      "save/filename\n",
      "save/Const\n",
      "save/SaveV2/tensor_names\n",
      "save/SaveV2/shape_and_slices\n",
      "save/SaveV2\n",
      "save/control_dependency\n",
      "save/RestoreV2/tensor_names\n",
      "save/RestoreV2/shape_and_slices\n",
      "save/RestoreV2\n",
      "save/Assign\n",
      "save/Assign_1\n",
      "save/Assign_2\n",
      "save/Assign_3\n",
      "save/Assign_4\n",
      "save/Assign_5\n",
      "save/Assign_6\n",
      "save/Assign_7\n",
      "save/Assign_8\n",
      "save/Assign_9\n",
      "save/Assign_10\n",
      "save/Assign_11\n",
      "save/Assign_12\n",
      "save/Assign_13\n",
      "save/Assign_14\n",
      "save/Assign_15\n",
      "save/Assign_16\n",
      "save/Assign_17\n",
      "save/Assign_18\n",
      "save/restore_all\n",
      "init\n"
     ]
    }
   ],
   "source": [
    "for _ in graph.get_operations():\n",
    "    print(_.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'ref/conv0/kernel:0' shape=(8, 4, 1) dtype=float32_ref>,\n",
       " <tf.Variable 'ref/bn/gamma:0' shape=(1,) dtype=float32_ref>,\n",
       " <tf.Variable 'ref/bn/beta:0' shape=(1,) dtype=float32_ref>,\n",
       " <tf.Variable 'ref/bn/moving_mean:0' shape=(1,) dtype=float32_ref>,\n",
       " <tf.Variable 'ref/bn/moving_variance:0' shape=(1,) dtype=float32_ref>,\n",
       " <tf.Variable 'ref/dense/kernel:0' shape=(93, 1) dtype=float32_ref>,\n",
       " <tf.Variable 'ref/dense/bias:0' shape=(1,) dtype=float32_ref>,\n",
       " <tf.Variable 'beta1_power:0' shape=() dtype=float32_ref>,\n",
       " <tf.Variable 'beta2_power:0' shape=() dtype=float32_ref>,\n",
       " <tf.Variable 'ref/conv0/kernel/Adam:0' shape=(8, 4, 1) dtype=float32_ref>,\n",
       " <tf.Variable 'ref/conv0/kernel/Adam_1:0' shape=(8, 4, 1) dtype=float32_ref>,\n",
       " <tf.Variable 'ref/bn/gamma/Adam:0' shape=(1,) dtype=float32_ref>,\n",
       " <tf.Variable 'ref/bn/gamma/Adam_1:0' shape=(1,) dtype=float32_ref>,\n",
       " <tf.Variable 'ref/bn/beta/Adam:0' shape=(1,) dtype=float32_ref>,\n",
       " <tf.Variable 'ref/bn/beta/Adam_1:0' shape=(1,) dtype=float32_ref>,\n",
       " <tf.Variable 'ref/dense/kernel/Adam:0' shape=(93, 1) dtype=float32_ref>,\n",
       " <tf.Variable 'ref/dense/kernel/Adam_1:0' shape=(93, 1) dtype=float32_ref>,\n",
       " <tf.Variable 'ref/dense/bias/Adam:0' shape=(1,) dtype=float32_ref>,\n",
       " <tf.Variable 'ref/dense/bias/Adam_1:0' shape=(1,) dtype=float32_ref>,\n",
       " <tf.Variable 'new_branch/new_conv/kernel:0' shape=(5, 1, 10) dtype=float32_ref>,\n",
       " <tf.Variable 'new_branch/new_conv/bias:0' shape=(10,) dtype=float32_ref>,\n",
       " <tf.Variable 'new_branch/new_bn/gamma:0' shape=(10,) dtype=float32_ref>,\n",
       " <tf.Variable 'new_branch/new_bn/beta:0' shape=(10,) dtype=float32_ref>,\n",
       " <tf.Variable 'new_branch/new_bn/moving_mean:0' shape=(10,) dtype=float32_ref>,\n",
       " <tf.Variable 'new_branch/new_bn/moving_variance:0' shape=(10,) dtype=float32_ref>,\n",
       " <tf.Variable 'new_branch/new_dense/kernel:0' shape=(890, 1) dtype=float32_ref>,\n",
       " <tf.Variable 'new_branch/new_dense/bias:0' shape=(1,) dtype=float32_ref>,\n",
       " <tf.Variable 'new_branch/beta1_power:0' shape=() dtype=float32_ref>,\n",
       " <tf.Variable 'new_branch/beta2_power:0' shape=() dtype=float32_ref>,\n",
       " <tf.Variable 'new_branch/new_branch/new_conv/kernel/new_opt:0' shape=(5, 1, 10) dtype=float32_ref>,\n",
       " <tf.Variable 'new_branch/new_branch/new_conv/kernel/new_opt_1:0' shape=(5, 1, 10) dtype=float32_ref>,\n",
       " <tf.Variable 'new_branch/new_branch/new_conv/bias/new_opt:0' shape=(10,) dtype=float32_ref>,\n",
       " <tf.Variable 'new_branch/new_branch/new_conv/bias/new_opt_1:0' shape=(10,) dtype=float32_ref>,\n",
       " <tf.Variable 'new_branch/new_branch/new_bn/gamma/new_opt:0' shape=(10,) dtype=float32_ref>,\n",
       " <tf.Variable 'new_branch/new_branch/new_bn/gamma/new_opt_1:0' shape=(10,) dtype=float32_ref>,\n",
       " <tf.Variable 'new_branch/new_branch/new_bn/beta/new_opt:0' shape=(10,) dtype=float32_ref>,\n",
       " <tf.Variable 'new_branch/new_branch/new_bn/beta/new_opt_1:0' shape=(10,) dtype=float32_ref>,\n",
       " <tf.Variable 'new_branch/new_branch/new_dense/kernel/new_opt:0' shape=(890, 1) dtype=float32_ref>,\n",
       " <tf.Variable 'new_branch/new_branch/new_dense/kernel/new_opt_1:0' shape=(890, 1) dtype=float32_ref>,\n",
       " <tf.Variable 'new_branch/new_branch/new_dense/bias/new_opt:0' shape=(1,) dtype=float32_ref>,\n",
       " <tf.Variable 'new_branch/new_branch/new_dense/bias/new_opt_1:0' shape=(1,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.global_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0911 22:00:56.037491 23448 deprecation.py:323] From <ipython-input-4-0d98f3637797>:5: conv1d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.keras.layers.Conv1D` instead.\n",
      "W0911 22:00:56.041487 23448 deprecation.py:506] From c:\\users\\yynst\\anaconda3\\envs\\gpu\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0911 22:00:56.137485 23448 deprecation.py:323] From <ipython-input-4-0d98f3637797>:6: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.BatchNormalization instead.  In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.batch_normalization` documentation).\n",
      "W0911 22:00:56.197486 23448 deprecation.py:323] From <ipython-input-4-0d98f3637797>:7: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "W0911 22:00:56.393487 23448 deprecation.py:323] From <ipython-input-4-0d98f3637797>:8: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n"
     ]
    }
   ],
   "source": [
    "with tf.variable_scope(name_or_scope='new_branch'):\n",
    "    tmp_op=graph.get_tensor_by_name('ref/drop/Identity:0')\n",
    "    # new ops\n",
    "    #new_tmp_op=tf.stop_gradient(tmp_op,name='stop_g')\n",
    "    new_op1=tf.layers.conv1d(inputs=tmp_op,filters=10,kernel_size=5,padding='valid',name='new_conv')\n",
    "    new_op2=tf.layers.batch_normalization(inputs=new_op1,axis=-1,name='new_bn')\n",
    "    new_op3=tf.layers.flatten(inputs=new_op2,name='new_flat')\n",
    "    new_op4=tf.layers.dense(inputs=new_op3,units=1,name='new_dense')\n",
    "\n",
    "with tf.variable_scope(name_or_scope='new_criteria'):\n",
    "    new_loss=tf.reduce_mean(tf.square(tf.subtract(graph.get_tensor_by_name('criteria/target:0'),new_op4)),name='new_loss') \n",
    "    new_opt=tf.train.AdamOptimizer(learning_rate=0.01,\n",
    "                 name='new_adam').minimize(new_loss,name='new_opt',\n",
    "                                 var_list=tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,scope='new'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### transfer training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0911 22:01:46.552486 23448 deprecation.py:323] From c:\\users\\yynst\\anaconda3\\envs\\gpu\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:1354: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "# need to only initialize the un-initialized ones\n",
    "initialize_uninitialized(sess)\n",
    "#print(graph.get_tensor_by_name('new_conv/kernel:0').eval(session=sess))\n",
    "# run new training \n",
    "for _ in range(10):\n",
    "        print(_)\n",
    "        sess.run([new_loss,new_opt],feed_dict={'ref/v1:0':seq,'criteria/target:0':label})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show new graph\n",
    "new_graph_def=tf.graph_util.extract_sub_graph(sess.graph_def,['ref/v1','new_criteria/new_opt'])\n",
    "writer = tf.summary.FileWriter(\"./model/model_graph\", graph=sess.graph,filename_suffix='new')\n",
    "#writer = tf.summary.FileWriter(\"./model/model_graph\", graph=sess.graph_def,filename_suffix='new')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-0.18694213],\n",
       "        [ 0.08943529],\n",
       "        [ 0.28633773],\n",
       "        [ 0.14845935]],\n",
       "\n",
       "       [[-0.19800441],\n",
       "        [ 0.26258618],\n",
       "        [ 0.0839562 ],\n",
       "        [ 0.03638361]],\n",
       "\n",
       "       [[-0.09319929],\n",
       "        [ 0.07355726],\n",
       "        [-0.3320895 ],\n",
       "        [-0.02227289]],\n",
       "\n",
       "       [[ 0.21407974],\n",
       "        [-0.22823995],\n",
       "        [ 0.09404552],\n",
       "        [ 0.05545748]],\n",
       "\n",
       "       [[ 0.21332948],\n",
       "        [-0.03028096],\n",
       "        [ 0.25843358],\n",
       "        [-0.30465853]],\n",
       "\n",
       "       [[-0.04313145],\n",
       "        [-0.19690534],\n",
       "        [ 0.12884268],\n",
       "        [ 0.02714686]],\n",
       "\n",
       "       [[-0.44813126],\n",
       "        [-0.00278444],\n",
       "        [-0.36645076],\n",
       "        [-0.27480653]],\n",
       "\n",
       "       [[ 0.16461603],\n",
       "        [ 0.28126273],\n",
       "        [-0.01375197],\n",
       "        [-0.28515607]]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get old weight matrix\n",
    "graph.get_tensor_by_name('ref/conv0/kernel:0').eval(session=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-0.18694213],\n",
       "        [ 0.08943529],\n",
       "        [ 0.28633773],\n",
       "        [ 0.14845935]],\n",
       "\n",
       "       [[-0.19800441],\n",
       "        [ 0.26258618],\n",
       "        [ 0.0839562 ],\n",
       "        [ 0.03638361]],\n",
       "\n",
       "       [[-0.09319929],\n",
       "        [ 0.07355726],\n",
       "        [-0.3320895 ],\n",
       "        [-0.02227289]],\n",
       "\n",
       "       [[ 0.21407974],\n",
       "        [-0.22823995],\n",
       "        [ 0.09404552],\n",
       "        [ 0.05545748]],\n",
       "\n",
       "       [[ 0.21332948],\n",
       "        [-0.03028096],\n",
       "        [ 0.25843358],\n",
       "        [-0.30465853]],\n",
       "\n",
       "       [[-0.04313145],\n",
       "        [-0.19690534],\n",
       "        [ 0.12884268],\n",
       "        [ 0.02714686]],\n",
       "\n",
       "       [[-0.44813126],\n",
       "        [-0.00278444],\n",
       "        [-0.36645076],\n",
       "        [-0.27480653]],\n",
       "\n",
       "       [[ 0.16461603],\n",
       "        [ 0.28126273],\n",
       "        [-0.01375197],\n",
       "        [-0.28515607]]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get new weight matrix\n",
    "graph.get_tensor_by_name('ref/conv0/kernel:0').eval(session=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"The name 'new_conv/kernel:0' refers to a Tensor which does not exist. The operation, 'new_conv/kernel', does not exist in the graph.\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-f5db85d0f1b8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_tensor_by_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'new_conv/kernel:0'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\yynst\\anaconda3\\envs\\panda\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mget_tensor_by_name\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   3970\u001b[0m       raise TypeError(\"Tensor names are strings (or similar), not %s.\" %\n\u001b[0;32m   3971\u001b[0m                       type(name).__name__)\n\u001b[1;32m-> 3972\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_graph_element\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3973\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3974\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_get_tensor_by_tf_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf_output\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\yynst\\anaconda3\\envs\\panda\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mas_graph_element\u001b[1;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[0;32m   3794\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3795\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3796\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_as_graph_element_locked\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3797\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3798\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_as_graph_element_locked\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\yynst\\anaconda3\\envs\\panda\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_as_graph_element_locked\u001b[1;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[0;32m   3836\u001b[0m           raise KeyError(\"The name %s refers to a Tensor which does not \"\n\u001b[0;32m   3837\u001b[0m                          \u001b[1;34m\"exist. The operation, %s, does not exist in the \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3838\u001b[1;33m                          \"graph.\" % (repr(name), repr(op_name)))\n\u001b[0m\u001b[0;32m   3839\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3840\u001b[0m           \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mout_n\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"The name 'new_conv/kernel:0' refers to a Tensor which does not exist. The operation, 'new_conv/kernel', does not exist in the graph.\""
     ]
    }
   ],
   "source": [
    "graph.get_tensor_by_name('new_conv/kernel:0').eval(session=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'ref/conv0/kernel:0' shape=(8, 4, 1) dtype=float32_ref>,\n",
       " <tf.Variable 'ref/bn/gamma:0' shape=(1,) dtype=float32_ref>,\n",
       " <tf.Variable 'ref/bn/beta:0' shape=(1,) dtype=float32_ref>,\n",
       " <tf.Variable 'ref/bn/moving_mean:0' shape=(1,) dtype=float32_ref>,\n",
       " <tf.Variable 'ref/bn/moving_variance:0' shape=(1,) dtype=float32_ref>,\n",
       " <tf.Variable 'ref/dense/kernel:0' shape=(93, 1) dtype=float32_ref>,\n",
       " <tf.Variable 'ref/dense/bias:0' shape=(1,) dtype=float32_ref>,\n",
       " <tf.Variable 'beta1_power:0' shape=() dtype=float32_ref>,\n",
       " <tf.Variable 'beta2_power:0' shape=() dtype=float32_ref>,\n",
       " <tf.Variable 'ref/conv0/kernel/Adam:0' shape=(8, 4, 1) dtype=float32_ref>,\n",
       " <tf.Variable 'ref/conv0/kernel/Adam_1:0' shape=(8, 4, 1) dtype=float32_ref>,\n",
       " <tf.Variable 'ref/bn/gamma/Adam:0' shape=(1,) dtype=float32_ref>,\n",
       " <tf.Variable 'ref/bn/gamma/Adam_1:0' shape=(1,) dtype=float32_ref>,\n",
       " <tf.Variable 'ref/bn/beta/Adam:0' shape=(1,) dtype=float32_ref>,\n",
       " <tf.Variable 'ref/bn/beta/Adam_1:0' shape=(1,) dtype=float32_ref>,\n",
       " <tf.Variable 'ref/dense/kernel/Adam:0' shape=(93, 1) dtype=float32_ref>,\n",
       " <tf.Variable 'ref/dense/kernel/Adam_1:0' shape=(93, 1) dtype=float32_ref>,\n",
       " <tf.Variable 'ref/dense/bias/Adam:0' shape=(1,) dtype=float32_ref>,\n",
       " <tf.Variable 'ref/dense/bias/Adam_1:0' shape=(1,) dtype=float32_ref>,\n",
       " <tf.Variable 'new_branch/new_conv/kernel:0' shape=(5, 1, 10) dtype=float32_ref>,\n",
       " <tf.Variable 'new_branch/new_conv/bias:0' shape=(10,) dtype=float32_ref>,\n",
       " <tf.Variable 'new_branch/new_bn/gamma:0' shape=(10,) dtype=float32_ref>,\n",
       " <tf.Variable 'new_branch/new_bn/beta:0' shape=(10,) dtype=float32_ref>,\n",
       " <tf.Variable 'new_branch/new_bn/moving_mean:0' shape=(10,) dtype=float32_ref>,\n",
       " <tf.Variable 'new_branch/new_bn/moving_variance:0' shape=(10,) dtype=float32_ref>,\n",
       " <tf.Variable 'new_branch/new_dense/kernel:0' shape=(890, 1) dtype=float32_ref>,\n",
       " <tf.Variable 'new_branch/new_dense/bias:0' shape=(1,) dtype=float32_ref>,\n",
       " <tf.Variable 'beta1_power_1:0' shape=() dtype=float32_ref>,\n",
       " <tf.Variable 'beta2_power_1:0' shape=() dtype=float32_ref>,\n",
       " <tf.Variable 'new_branch/new_conv/kernel/new_opt:0' shape=(5, 1, 10) dtype=float32_ref>,\n",
       " <tf.Variable 'new_branch/new_conv/kernel/new_opt_1:0' shape=(5, 1, 10) dtype=float32_ref>,\n",
       " <tf.Variable 'new_branch/new_conv/bias/new_opt:0' shape=(10,) dtype=float32_ref>,\n",
       " <tf.Variable 'new_branch/new_conv/bias/new_opt_1:0' shape=(10,) dtype=float32_ref>,\n",
       " <tf.Variable 'new_branch/new_bn/gamma/new_opt:0' shape=(10,) dtype=float32_ref>,\n",
       " <tf.Variable 'new_branch/new_bn/gamma/new_opt_1:0' shape=(10,) dtype=float32_ref>,\n",
       " <tf.Variable 'new_branch/new_bn/beta/new_opt:0' shape=(10,) dtype=float32_ref>,\n",
       " <tf.Variable 'new_branch/new_bn/beta/new_opt_1:0' shape=(10,) dtype=float32_ref>,\n",
       " <tf.Variable 'new_branch/new_dense/kernel/new_opt:0' shape=(890, 1) dtype=float32_ref>,\n",
       " <tf.Variable 'new_branch/new_dense/kernel/new_opt_1:0' shape=(890, 1) dtype=float32_ref>,\n",
       " <tf.Variable 'new_branch/new_dense/bias/new_opt:0' shape=(1,) dtype=float32_ref>,\n",
       " <tf.Variable 'new_branch/new_dense/bias/new_opt_1:0' shape=(1,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.global_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0905 16:16:44.739183 11996 writer.py:199] Passing a `GraphDef` to the SummaryWriter is deprecated. Pass a `Graph` object instead, such as `sess.graph`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v1\n",
      "v2\n",
      "Add\n",
      "vx/initial_value\n",
      "vx\n",
      "vx/Assign\n",
      "vx/read\n",
      "v4_op\n",
      "v5/y\n",
      "v5\n",
      "save/filename/input\n",
      "save/filename\n",
      "save/Const\n",
      "save/SaveV2/tensor_names\n",
      "save/SaveV2/shape_and_slices\n",
      "save/SaveV2\n",
      "save/control_dependency\n",
      "save/RestoreV2/tensor_names\n",
      "save/RestoreV2/shape_and_slices\n",
      "save/RestoreV2\n",
      "save/Assign\n",
      "save/restore_all\n",
      "init\n",
      "Add_1\n",
      "Assign\n",
      "\n",
      "3.53\n",
      "\n",
      "v1\n",
      "v2\n",
      "Add\n",
      "vx\n",
      "vx/read\n",
      "v4_op\n",
      "truediv/y\n",
      "truediv\n",
      "new_v5\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "with tf.Session() as sess: \n",
    "    saver = tf.train.import_meta_graph(\"./model/model_test.meta\")\n",
    "    saver.restore(sess,tf.train.latest_checkpoint('./model/'))\n",
    "    #tf.saved_model.load(sess,tags=[tf.saved_model.tag_constants.SERVING],export_dir='./model/model_ex1')\n",
    "   \n",
    "  \n",
    "    for op in tf.get_default_graph().get_operations():\n",
    "        print(op.name) \n",
    "#     print(tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES))\n",
    "    graph=tf.get_default_graph()\n",
    "    op=graph.get_tensor_by_name('v4_op:0')\n",
    "    new_op=tf.divide(op,10)\n",
    "    new_op=tf.identity(new_op,name='new_v5')\n",
    "    result = sess.run(new_op, \n",
    "                      feed_dict={\"v1:0\": 12.0, \"v2:0\": 3.3})  \n",
    "    \n",
    "    #print(sess.graph_def)\n",
    "    # the problem with Basenji is that the input feed_dict is not known with pre-trained model\n",
    "    #print(sess.graph_def)\n",
    "    new_graph_def=tf.graph_util.extract_sub_graph(sess.graph_def,['v1','v2','vx','v4_op','new_v5'])  # extract subgraph accessible to destination nodes defined here\n",
    "    \n",
    "    # this can still output modified graph, but only for visualization\n",
    "    writer = tf.summary.FileWriter(\"./model/model_ex3/model_graph\", graph=new_graph_def,filename_suffix='new')\n",
    "    #writer = tf.summary.FileWriter(\"./model/model_ex3/model_graph\", graph=sess.graph,filename_suffix='old')\n",
    "    print()\n",
    "    print(result)\n",
    "    print()\n",
    "    for _ in new_graph_def.node:\n",
    "        print(_.name)\n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "['trainable_variables', 'variables']\n",
      "[<tf.Variable 'vx:0' shape=() dtype=float32_ref>]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Operation 'v5' type=Pow>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph=tf.get_default_graph()\n",
    "print()\n",
    "print(graph.get_all_collection_keys())\n",
    "print(tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES))\n",
    "#graph.get_operations()\n",
    "graph.get_tensor_by_name('vx:0')\n",
    "\n",
    "graph.get_operation_by_name('v5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
